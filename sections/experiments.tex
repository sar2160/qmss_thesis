
\section{Experiments}
\label{experiments}

Both long- and short-term prediction and forecasting experiments were considered, as well as both neighborhood level spatial granularity and a larger city level scheme. A summary of each is provided in the table below:

\begin{table}[]
\centering
\caption{Models Considered}
\label{model_summary}
\begin{tabular}{@{}llllll@{}}
\toprule
Outlook     & Spatial Feature & Frequency & Fitting Period & Look-Ahead Period & Stationary \\ \midrule
Long-Term   & None            & Weekly    & 3 years        & 52 Weeks          & No         \\
Medium-Term & Neighborhoods   & Weekly    & 1 year         & 26 Weeks          & Yes        \\
Short-Term  & Grid Squares    & Weekly    & 6  weeks       & 12 Weeks          & Yes        \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Kernel Choice}

The kernel types specified for each $k$ differed slightly from Flaxman 2014 after experimenting with various configurations. Table \ref{kernel_summary} describes the kernel combinations used for each model. Other combinations were considered, including using variations of the Matern class and varying the interaction term, but none exhibited better performance.


\begin{table}[]
\centering
\caption{Kernel Specifications}
\label{kernel_summary}
\begin{tabular}{@{}llllll@{}}
\toprule
            & Temporal & Spatial  & Periodic & Product            & Linear \\ \midrule
Long-Term   & RBF      & No       & Yes      & No                 & Yes    \\
Medium-Term & RBF      & Matern32 & Yes      & Spatial x Temporal & No     \\
Short-Term  & RBF      & RBF      & Yes      & Spatial x Temporal & No     \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Data Cleaning}

Since vehicle collisions are reported directly by responding public safety personnel they are not subject to the reporting bias it would be plausible to find in complaint/report data like 311, which would have added an additional source of potential bias. Crashes without latitude and longitude were excluded, as well as any crashes that happened on highways and other high-speed motorways in the city

\subsection{GPflow}

GPflow is a Python package developed for fitting Gaussian Process models that takes advantage of the autodifferentiation abilities of Google's TensorFlow to generate Maximum-A-Posteriori (MAP) estimates of the posterior distribution \cite{GPflow2017} \cite{tensorflow2015-whitepaper}. All models are converted into tensors and passed to Tensorflow's optimization algorithms that can run on Graphics Processing Units (GPUs) for fast and efficient computation. This cuts the time needed for each iteration significantly compared to running on a CPU and also doesn't restrict the user to using conjugate distributions when specifying priors and likelihoods - a prerequisite for the LGCP model. GPflow is also capable of full Bayesian inference using Hamiltonian Monte Carlo (HMC).

\subsubsection{Custom Modifications}

While GPflow offers most of the settings required 'out-of-the-box', a few additional features had to be added independently. The base package does not offer the option for a Student-T prior, which was relatively easy to add by writing a new custom Student-T class to GPflow. The package also by default does not easily allow for decomposition of the different kernels' contribution to the parameter estimates. Finally, the GPflow implementation of Matern kernels often exhibit unstable behavior and, even after re-centering data. A small jitter was added to the Matern32 kernel in in order to reduce the chance of the Cholesky Decomposition failing. All modifications can be found in the appendix \todo(cite to appendix code).
